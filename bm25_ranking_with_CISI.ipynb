{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eduseiti/bm25_explore/blob/main/bm25_ranking_with_CISI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYZz782gn2WR",
    "outputId": "9bc85f7a-0843-4049-f38e-b069a1e4d7a9"
   },
   "outputs": [],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcKElOJru9AF"
   },
   "outputs": [],
   "source": [
    "import rank_bm25\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import regex as re\n",
    "import urllib\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7YbT7SNFBkX",
    "outputId": "a7770917-69a5-4006-9bcb-4b9208c2eddd"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4c8OXx_IVaC"
   },
   "outputs": [],
   "source": [
    "PARSING_FIELDS_REGEXS={\n",
    "    'identifier': [\"^\\.I\\s+([0-9]+)\"],\n",
    "    'title_or_words': [\"^\\.T\\s*\\r?\\n?$|^\\.W\\s*\\r?\\n?$\"],\n",
    "    'title_content_or_author': [\"^\\.A\\s*\\r?\\n?$\", \"^(.+)\\r\\n$|^(.+)\\n$\"],\n",
    "    'author_content_or_words': [\"^\\.W\\s*\\r?\\n?$\", \"^(.+)\\r\\n$|^(.+)\\n$\"],\n",
    "    'words_content_or_xref_or_identifier': [\"^\\.I\\s+([0-9]+)\", \"^\\.X\\s*\\r?\\n?$\", \"^(.+)\\r\\n$|^(.+)\\n$\"],\n",
    "    'words_content_or_identifier': [\"^\\.I\\s+([0-9]+)\", \"^(.+)\\r\\n$|^(.+)\\n$\"],\n",
    "    'xref_content_or_identifier': [\"^\\.I\\s+([0-9]+)\", \"^(.+)\\r\\n$|^(.+)\\n$\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4c8OXx_IVaC"
   },
   "outputs": [],
   "source": [
    "def read_cisi_docs_and_queries(file_url):\n",
    "\n",
    "    all_elements = []\n",
    "\n",
    "    current_element = {'next_field': 'identifier'}\n",
    "\n",
    "    for line in urllib.request.urlopen(file_url):\n",
    "\n",
    "        # print(line)\n",
    "        # print(current_element)\n",
    "\n",
    "        regex_list = PARSING_FIELDS_REGEXS[current_element['next_field']]\n",
    "\n",
    "        for each_regex in regex_list:\n",
    "            m = re.match(each_regex, line.decode())\n",
    "\n",
    "            if m is not None:\n",
    "                break;\n",
    "\n",
    "        if m is not None:\n",
    "            # Check if this match has data to store\n",
    "\n",
    "            if len(m.groups()) > 0:\n",
    "\n",
    "                # As there is data, check what it is and store it properly\n",
    "\n",
    "                if current_element['next_field'] == 'identifier':\n",
    "                    current_element['identifier'] = m.group(1)\n",
    "                    current_element['next_field'] = 'title_or_words'\n",
    "\n",
    "                elif current_element['next_field'] == 'title_content_or_author':\n",
    "                    current_element['title'] += m.group(1) + ' '\n",
    "\n",
    "                elif current_element['next_field'] == 'author_content_or_words':\n",
    "                    current_element['author'] += m.group(1) + ';'\n",
    "\n",
    "                elif (current_element['next_field'] == 'xref_content_or_identifier') or \\\n",
    "                     (current_element['next_field'] == 'words_content_or_identifier') or \\\n",
    "                     (current_element['next_field'] == 'words_content_or_xref_or_identifier'):\n",
    "\n",
    "                    if m.group(0)[0:2] == '.I':\n",
    "                        # Document complete\n",
    "\n",
    "                        # print(current_element)\n",
    "\n",
    "                        all_elements.append(current_element)\n",
    "\n",
    "                        current_element = {'identifier': m.group(1),\n",
    "                                           'next_field': 'title_or_words'}\n",
    "                    else:\n",
    "                        if current_element['next_field'] == 'xref_content_or_identifier':\n",
    "                            current_element['xref'] += m.group(1) + ';'\n",
    "                        else:\n",
    "                            if m.group(1) is not None:\n",
    "                                current_element['words'] += m.group(1) + ' '\n",
    "\n",
    "            else:\n",
    "\n",
    "                # This is a tag-only entry\n",
    "\n",
    "                if current_element['next_field'] == 'title_or_words':\n",
    "                    if m.group(0)[0:2] == '.T':\n",
    "                        current_element['title'] = \"\"\n",
    "                        current_element['next_field'] = 'title_content_or_author'\n",
    "                    else:\n",
    "                        current_element['words'] = \"\"\n",
    "                        current_element['next_field'] = 'words_content_or_identifier'\n",
    "\n",
    "                elif current_element['next_field'] == 'title_content_or_author':\n",
    "                    current_element['author'] = \"\"\n",
    "                    current_element['next_field'] = 'author_content_or_words'\n",
    "\n",
    "                elif current_element['next_field'] == 'author_content_or_words':\n",
    "                    current_element['words'] = \"\"\n",
    "                    current_element['next_field'] = 'words_content_or_xref_or_identifier'\n",
    "\n",
    "                elif current_element['next_field'] == 'words_content_or_xref_or_identifier':\n",
    "                    current_element['xref'] = \"\"\n",
    "                    current_element['next_field'] = 'xref_content_or_identifier'\n",
    "\n",
    "                elif (current_element['next_field'] == 'xref_content_or_identifier') \\\n",
    "                     (current_element['next_field'] == 'words_content_or_identifier'):\n",
    "\n",
    "                    # Document complete\n",
    "\n",
    "                    # print(current_element)\n",
    "\n",
    "                    all_elements.append(current_element)\n",
    "\n",
    "                    current_element = {'next_field': 'identifier'}\n",
    "\n",
    "                else:\n",
    "                    print(\"Just ignore the line\")\n",
    "\n",
    "        # break\n",
    "\n",
    "    if current_element['next_field'] != 'title_or_words':\n",
    "        all_elements.append(current_element)\n",
    "\n",
    "    print(\"Parsed {} elements...\".format(len(all_elements)))  \n",
    "\n",
    "    return pd.DataFrame(all_elements).drop(columns='next_field')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLzZ1cYqDxsC"
   },
   "source": [
    "# Read CISI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzt2rb2uzXB9",
    "outputId": "b68859c8-743c-4234-f305-c958ae2a2f83"
   },
   "outputs": [],
   "source": [
    "docs_df = read_cisi_docs_and_queries('https://raw.githubusercontent.com/eduseiti/bm25_explore/main/cisi/CISI.ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyBGYQux2pd_",
    "outputId": "51b54075-9893-4c12-8074-da14d08be702"
   },
   "outputs": [],
   "source": [
    "queries_df = read_cisi_docs_and_queries('https://raw.githubusercontent.com/eduseiti/bm25_explore/main/cisi/CISI.QRY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDYz564C2oeB"
   },
   "outputs": [],
   "source": [
    "qrels_df = pd.read_csv('https://raw.githubusercontent.com/eduseiti/bm25_explore/main/cisi/CISI.REL', \n",
    "                       sep='\\t', \n",
    "                       header=None, \n",
    "                       names=['query_id', 'doc_id', 'Q0', 'rel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIEvmtGHGOYY"
   },
   "source": [
    "# Tokenize and clean stop words from reference docs and queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqkM2p5gAhDk"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stop_words(which_df, stop_words, punctuation):\n",
    "\n",
    "    all_tokens = [nltk.word_tokenize(doc.lower()) for doc in which_df['words']]\n",
    "\n",
    "    cleaned_tokens = [[token for token in doc_tokens if token not in stop_words and token not in punctuation] for doc_tokens in all_tokens]\n",
    "\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlOUyDyBEm5u"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bEoejvoYEAz"
   },
   "outputs": [],
   "source": [
    "docs_tokens = tokenize_and_remove_stop_words(docs_df, stop_words, punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW1_OK3nE3K_",
    "outputId": "dce5afd6-22d7-427b-ee04-9301a88731ad"
   },
   "outputs": [],
   "source": [
    "len(docs_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1jcM51NFhsl"
   },
   "outputs": [],
   "source": [
    "queries_tokens = tokenize_and_remove_stop_words(queries_df, stop_words, punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkI39YaLF3jU",
    "outputId": "919386fd-738e-4e6a-ee1d-0c5f77bc3ad4"
   },
   "outputs": [],
   "source": [
    "len(queries_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdHeOT-jGA3q"
   },
   "source": [
    "# Compute BM25 scores for each query / document pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dC2gPqKg4L4K"
   },
   "outputs": [],
   "source": [
    "def compute_BM25(docs_tokens, queries_tokens, qrels_df, bm25_params, score_threshold = 1e-5):\n",
    "\n",
    "    # print(\"k1={}, b={}\".format(k1, b))\n",
    "\n",
    "    docs_bm25_scores = rank_bm25.BM25Okapi(docs_tokens, k1=bm25_params[0], b=bm25_params[1])\n",
    "\n",
    "    docs_queries_scores = []\n",
    "\n",
    "    for query_tokens in queries_tokens:\n",
    "        query_scores = docs_bm25_scores.get_scores(query_tokens)\n",
    "\n",
    "        docs_queries_scores.append(query_scores)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Evaluate the retrieval performance using precision, recall, and F1-score\n",
    "\n",
    "    query_ids = qrels_df['query_id'].unique()\n",
    "\n",
    "    for query_id in query_ids:\n",
    "\n",
    "        inferred_relevant_docs = docs_queries_scores[query_id - 1] > score_threshold\n",
    "\n",
    "        gt_relevant_docs = np.zeros(inferred_relevant_docs.shape[0], dtype=bool)\n",
    "        gt_relevant_docs[qrels_df[qrels_df['query_id'] == query_id]['doc_id'].to_numpy() - 1] = True\n",
    "\n",
    "        precision = precision_score(gt_relevant_docs, inferred_relevant_docs)\n",
    "        recall = recall_score(gt_relevant_docs, inferred_relevant_docs)\n",
    "        f1 = f1_score(gt_relevant_docs, inferred_relevant_docs)\n",
    "\n",
    "        results.append({'query_id': query_id,\n",
    "                        'k1': bm25_params[0],\n",
    "                        'b': bm25_params[1],\n",
    "                        'score_threshold': score_threshold,\n",
    "                        'precision': precision, \n",
    "                        'recall': recall, \n",
    "                        'f1': f1})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_score_threshold(docs_tokens, queries_tokens, qrels_df, k1, b, score_thresholds):\n",
    "    \n",
    "    docs_bm25_scores = rank_bm25.BM25Okapi(docs_tokens, k1=k1, b=b)\n",
    "    \n",
    "    docs_queries_scores = []\n",
    "\n",
    "    for query_tokens in queries_tokens:\n",
    "        query_scores = docs_bm25_scores.get_scores(query_tokens)\n",
    "\n",
    "        docs_queries_scores.append(query_scores)\n",
    "\n",
    "    query_ids = qrels_df['query_id'].unique()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for score_threshold in score_thresholds:\n",
    "        \n",
    "        print(\"Evaluating score threshold={:.2f}...\".format(score_threshold))\n",
    "        \n",
    "        for query_id in query_ids:\n",
    "\n",
    "            inferred_relevant_docs = docs_queries_scores[query_id - 1] > score_threshold\n",
    "\n",
    "            gt_relevant_docs = np.zeros(inferred_relevant_docs.shape[0], dtype=bool)\n",
    "            gt_relevant_docs[qrels_df[qrels_df['query_id'] == query_id]['doc_id'].to_numpy() - 1] = True\n",
    "\n",
    "            precision = precision_score(gt_relevant_docs, inferred_relevant_docs)\n",
    "            recall = recall_score(gt_relevant_docs, inferred_relevant_docs)\n",
    "            f1 = f1_score(gt_relevant_docs, inferred_relevant_docs)\n",
    "\n",
    "            results.append({'query_id': query_id,\n",
    "                            'k1': k1,\n",
    "                            'b': b,\n",
    "                            'score_threshold': score_threshold,\n",
    "                            'precision': precision, \n",
    "                            'recall': recall, \n",
    "                            'f1': f1})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    results_stats_df = results_df.groupby(['score_threshold'])[['precision', 'recall', 'f1']].mean().reset_index()\n",
    "    \n",
    "    return results_df, results_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search on BM25 hyperparameters and fixed score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nnz5800IH07"
   },
   "outputs": [],
   "source": [
    "k1_values = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "b_values = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_parameters = list(product(k1_values, b_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nde2ghPaJI8T",
    "outputId": "6811cfd0-28f9-411c-8552-47bcde8100fe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Pool(processes=6) as pool:\n",
    "    all_results = pool.starmap(compute_BM25, zip([docs_tokens] * len(bm25_parameters),\n",
    "                                                 [queries_tokens] * len(bm25_parameters),\n",
    "                                                 [qrels_df] * len(bm25_parameters),\n",
    "                                                 bm25_parameters,\n",
    "                                                 [5] * len(bm25_parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8d9mRV9Jylz"
   },
   "outputs": [],
   "source": [
    "all_results_df = pd.concat(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byqit2dWSrL3"
   },
   "outputs": [],
   "source": [
    "all_results_stats_df = all_results_df.groupby(['k1', 'b'])[['precision', 'recall', 'f1']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "MxmKZs_PVavw",
    "outputId": "185ad13e-13d5-48b3-c6f0-fe1618d88fe1"
   },
   "outputs": [],
   "source": [
    "all_results_stats_df[all_results_stats_df['recall'] == all_results_stats_df['recall'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_stats_df[all_results_stats_df['precision'] == all_results_stats_df['precision'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to define the best BM25 score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresholds = np.arange(1, 20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try applying the BM25 hyperparameters with the best recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, results_stats_df = check_score_threshold(docs_tokens, queries_tokens, qrels_df, 2.0, 0.2, score_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stats_df[results_stats_df['recall'] == results_stats_df['recall'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stats_df[results_stats_df['precision'] == results_stats_df['precision'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stats_df[results_stats_df['f1'] == results_stats_df['f1'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, check the BM25 hyperparameters with best precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_2_df, results_2_stats_df = check_score_threshold(docs_tokens, queries_tokens, qrels_df, 1.0, 0.55, score_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_stats_df[results_2_stats_df['recall'] == results_2_stats_df['recall'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_stats_df[results_2_stats_df['precision'] == results_2_stats_df['precision'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_stats_df[results_2_stats_df['f1'] == results_2_stats_df['f1'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOZ4RpA5IFy9YOcwBhS4lod",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
